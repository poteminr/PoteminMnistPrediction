{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import reshape\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab, gridspec\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop([\"label\"], axis = 1)\n",
    "y_train = pd.get_dummies(data_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-b6f9d8990cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 2 на 2 матрица\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 156,650\n",
      "Trainable params: 156,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29399 samples, validate on 12601 samples\n",
      "Epoch 1/19\n",
      "29399/29399 [==============================] - 43s 1ms/step - loss: 0.0667 - acc: 0.9813 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "Epoch 2/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.0657 - acc: 0.9817 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 3/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0655 - acc: 0.9811 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 4/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0646 - acc: 0.9810 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 5/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.0634 - acc: 0.9824 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 6/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.0651 - acc: 0.9817 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 7/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0637 - acc: 0.9823 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 8/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0688 - acc: 0.9811 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "Epoch 9/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.0652 - acc: 0.9815 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999424161285e-20.\n",
      "Epoch 10/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.0670 - acc: 0.9810 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-21.\n",
      "Epoch 11/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0651 - acc: 0.9812 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-22.\n",
      "Epoch 12/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0639 - acc: 0.9820 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-23.\n",
      "Epoch 13/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0651 - acc: 0.9823 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999682655227e-24.\n",
      "Epoch 14/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0632 - acc: 0.9815 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999998199588e-25.\n",
      "Epoch 15/19\n",
      "29399/29399 [==============================] - 52s 2ms/step - loss: 0.0697 - acc: 0.9808 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000195414814e-25.\n",
      "Epoch 16/19\n",
      "29399/29399 [==============================] - 49s 2ms/step - loss: 0.0662 - acc: 0.9816 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000195414814e-26.\n",
      "Epoch 17/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0645 - acc: 0.9811 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999887266024e-28.\n",
      "Epoch 18/19\n",
      "29399/29399 [==============================] - 47s 2ms/step - loss: 0.0676 - acc: 0.9809 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000272452012e-28.\n",
      "Epoch 19/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0637 - acc: 0.9819 - val_loss: 0.0327 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000031710769e-29.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5dce067cc0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=19, verbose=1, validation_split=0.3, callbacks=[lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test.values.reshape(data_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong pred and True predict percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict(X_train).argmax(1)\n",
    "data_wrong_pred = data_train[data_train[\"label\"] != pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True predict percent: 98.85357142857143 %\n"
     ]
    }
   ],
   "source": [
    "truepredpercent = 100 - len(data_wrong_pred) / len(data_test) * 100\n",
    "print('True predict percent: ' + str(truepredpercent) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b33ad329b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mreadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-4b33ad329b8e>\u001b[0m in \u001b[0;36mreadImages\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./hr/{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mreadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def readImages():\n",
    "    answers = list()\n",
    "    true = list()\n",
    "    for i in range(10):\n",
    "        l = listdir(\"./hr/{}/\".format(i))\n",
    "        true.extend([int(x[0]) for x in l])\n",
    "        for image in l:\n",
    "            img = np.array([255 - x for x in np.asarray(Image.open(\"./hr/{}/{}\".format(i, image)).convert(\"L\")).reshape(784,)]).reshape(28, 28)\n",
    "            answers.append(np.argmax(model.predict(np.array([img]).reshape(1, 28, 28, 1))[0]))\n",
    "    return accuracy_score(true, answers)\n",
    "k =readImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readImages():\n",
    "    answers = list()\n",
    "    true = list()\n",
    "    l = listdir(\"./hr/12345/\")\n",
    "    true.extend([int(x[0]) for x in l])\n",
    "    for image in l:\n",
    "        img = np.array([255 - x for x in np.asarray(Image.open(\"./hr/12345/{}\".format(image)).convert(\"L\")).reshape(784,)]).reshape(28, 28)\n",
    "        answers.append(np.argmax(model.predict(np.array([img]).reshape(1, 28, 28, 1))[0]))\n",
    "    return accuracy_score(true, answers)\n",
    "readImages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
