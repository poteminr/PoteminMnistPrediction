{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import reshape\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab, gridspec\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop([\"label\"], axis = 1)\n",
    "y_train = pd.get_dummies(data_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 2 на 2 матрица\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 156,650\n",
      "Trainable params: 156,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29399 samples, validate on 12601 samples\n",
      "Epoch 1/19\n",
      "29399/29399 [==============================] - 71s 2ms/step - loss: 1.3093 - acc: 0.6320 - val_loss: 0.1926 - val_acc: 0.9435\n",
      "Epoch 2/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.2350 - acc: 0.9314 - val_loss: 0.0724 - val_acc: 0.9774\n",
      "Epoch 3/19\n",
      "29399/29399 [==============================] - 45s 2ms/step - loss: 0.1423 - acc: 0.9595 - val_loss: 0.0499 - val_acc: 0.9840\n",
      "Epoch 4/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.1169 - acc: 0.9674 - val_loss: 0.0411 - val_acc: 0.9868\n",
      "Epoch 5/19\n",
      "29399/29399 [==============================] - 69s 2ms/step - loss: 0.0912 - acc: 0.9742 - val_loss: 0.0382 - val_acc: 0.9894\n",
      "Epoch 6/19\n",
      "29399/29399 [==============================] - 57s 2ms/step - loss: 0.0787 - acc: 0.9789 - val_loss: 0.0358 - val_acc: 0.9898\n",
      "Epoch 7/19\n",
      "29399/29399 [==============================] - 48s 2ms/step - loss: 0.0722 - acc: 0.9800 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.1.\n",
      "Epoch 8/19\n",
      "29399/29399 [==============================] - 58s 2ms/step - loss: 0.0475 - acc: 0.9874 - val_loss: 0.0257 - val_acc: 0.9929\n",
      "Epoch 9/19\n",
      "29399/29399 [==============================] - 58s 2ms/step - loss: 0.0427 - acc: 0.9886 - val_loss: 0.0260 - val_acc: 0.9932\n",
      "Epoch 10/19\n",
      "29399/29399 [==============================] - 69s 2ms/step - loss: 0.0396 - acc: 0.9881 - val_loss: 0.0259 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 11/19\n",
      "29399/29399 [==============================] - 53s 2ms/step - loss: 0.0404 - acc: 0.9891 - val_loss: 0.0254 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 12/19\n",
      "29399/29399 [==============================] - 47s 2ms/step - loss: 0.0374 - acc: 0.9890 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 13/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0382 - acc: 0.9894 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 14/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0365 - acc: 0.9891 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 15/19\n",
      "29399/29399 [==============================] - 47s 2ms/step - loss: 0.0400 - acc: 0.9890 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 16/19\n",
      "29399/29399 [==============================] - 47s 2ms/step - loss: 0.0392 - acc: 0.9891 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 17/19\n",
      "29399/29399 [==============================] - 47s 2ms/step - loss: 0.0374 - acc: 0.9897 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 18/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0411 - acc: 0.9887 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 19/19\n",
      "29399/29399 [==============================] - 46s 2ms/step - loss: 0.0391 - acc: 0.9884 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e2344cbe0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=19, verbose=1, validation_split=0.3, callbacks=[lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test.values.reshape(data_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong pred and True predict percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict(X_train).argmax(1)\n",
    "data_wrong_pred = data_train[data_train[\"label\"] != pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True predict percent: 98.85357142857143 %\n"
     ]
    }
   ],
   "source": [
    "truepredpercent = 100 - len(data_wrong_pred) / len(data_test) * 100\n",
    "print('True predict percent: ' + str(truepredpercent) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def readImages():\n",
    "    answers = list()\n",
    "    true = list()\n",
    "    for i in range(10):\n",
    "        l = listdir(\"./hr/{}/\".format(i))\n",
    "        true.extend([int(x[0]) for x in l])\n",
    "        for image in l:\n",
    "            img = np.array([255 - x for x in np.asarray(Image.open(\"./hr/{}/{}\".format(i, image)).convert(\"L\")).reshape(784,)]).reshape(28, 28)\n",
    "            answers.append(np.argmax(model.predict(np.array([img]).reshape(1, 28, 28, 1))[0]))\n",
    "    return accuracy_score(true, answers)\n",
    "k =readImages()\n",
    "print('Accuracy: '+ str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "def readImages():\n",
    "    answers = list()\n",
    "    true = list()\n",
    "    l = listdir(\"./hr/12345/\")\n",
    "    true.extend([int(x[0]) for x in l])\n",
    "    for image in l:\n",
    "        img = np.array([255 - x for x in np.asarray(Image.open(\"./hr/12345/{}\".format(image)).convert(\"L\")).reshape(784,)]).reshape(28, 28)\n",
    "        answers.append(np.argmax(model.predict(np.array([img]).reshape(1, 28, 28, 1))[0]))\n",
    "    return accuracy_score(true, answers)\n",
    "f = readImages()\n",
    "print('Accuracy: '+ str(f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
