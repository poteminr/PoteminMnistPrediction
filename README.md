# Recognition of handwritten digits from the mnist data-set, as well as recognition of the custom data-set drawn in Photoshop



НС для классификации картинок с одним цветовым каналом (градации серого) размером 28 x 28 пикселей. Классифицируются 10 различных объектов / классов  с 10 нейронами и функцией активации softmax.

softmax возвращает вероятность принадлежности картинки к каждому классу. Т.е. на выходе получается матрица с 10-ю столбцами (один столбец на каждый класс) с вероятностями.

Слой Dense - это простой полносвязный слой, когда каждый нейрон предыдущего слоя связан с каждым нейроном данного. Обычно во всех сверточных сетях в последних слоях используют 2-3 полносвязных слоя, которые следуют за слоями свертки, пулинга и "выпрямления" (слой: Flatten).

слой Flatten - "выпрямляет" 2+-мерные матрицы в одномерные вектора. Например из матрицы размерности (64, 32, 32) получится одномерный вектор с 64 * 32 * 32 = 65536 элементов.

Dropout - один из методов регуляризации (используется для борьбы с переобучением).

relu - одна из самых популярных нелинейных функций активации нейронов:

f(x) = max(0, x)

MaxPooling2D(pool_size=(2, 2)) проплывает окошком размером (2, 2) по матрице и для каждого окошка выбирает максимальное значение, уменьшая размер исходной матрицы

![alt text](https://github.com/poteminr/PoteminMnistPrediction/blob/master/logo.jpg)
